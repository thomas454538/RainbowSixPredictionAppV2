# PrÃ©diction des Victoires dans Rainbow Six Siege ğŸ®

Ce projet est une application de prÃ©diction qui utilise un **modÃ¨le d'ensemble d'arbres de dÃ©cision** pour estimer si le nombre de victoires d'un joueur dans Rainbow Six Siege est supÃ©rieur ou infÃ©rieur Ã  la mÃ©diane. L'usage d'un modÃ¨le d'ensemble amÃ©liore la prÃ©cision et la robustesse en combinant les rÃ©sultats de plusieurs arbres de dÃ©cision.

## ğŸ† ModÃ¨le UtilisÃ© : Ensemble d'Arbres de DÃ©cision

Le modÃ¨le d'ensemble d'arbres de dÃ©cision utilisÃ© dans ce projet est une technique avancÃ©e de machine learning qui amÃ©liore la performance en combinant les prÃ©dictions de plusieurs arbres de dÃ©cision individuels. Voici une explication dÃ©taillÃ©e de chaque Ã©tape du processus et des choix de paramÃ©trage :

### Principe de lâ€™Ensemble d'Arbres de DÃ©cision

Un arbre de dÃ©cision unique peut Ãªtre sensible aux variations des donnÃ©es d'entraÃ®nement, conduisant parfois Ã  des erreurs dues au surapprentissage (overfitting) ou Ã  la variabilitÃ© des prÃ©dictions. L'approche dâ€™ensemble rÃ©sout ce problÃ¨me en combinant plusieurs arbres de dÃ©cision indÃ©pendants, chacun construit sur un sous-Ã©chantillon diffÃ©rent de lâ€™ensemble dâ€™entraÃ®nement. Cela stabilise et renforce la prÃ©cision des prÃ©dictions globales.

### Ã‰tapes du ModÃ¨le

1. **Ã‰chantillonnage Bootstrap** :
   - **Processus** : Pour chaque arbre, un Ã©chantillon alÃ©atoire avec remise est extrait de lâ€™ensemble dâ€™entraÃ®nement. Cet Ã©chantillonnage avec remise signifie que certains Ã©chantillons peuvent Ãªtre choisis plusieurs fois, tandis que d'autres peuvent Ãªtre exclus du sous-Ã©chantillon.
   - **But** : Cette technique, connue sous le nom de "bagging" (Bootstrap Aggregating), permet de crÃ©er de la diversitÃ© parmi les arbres de l'ensemble. Un modÃ¨le plus diversifiÃ© est souvent plus robuste et moins sujet aux erreurs systÃ©matiques.
2. **EntraÃ®nement de chaque Arbre** :
   - **Structure de l'arbre** : Chaque arbre de dÃ©cision est limitÃ© Ã  une profondeur maximale de 5 niveaux, ce qui rÃ©duit la complexitÃ© de l'arbre et aide Ã  Ã©viter le surapprentissage. En restreignant la profondeur, chaque arbre est lÃ©gÃ¨rement biaisÃ©, mais ce biais est corrigÃ© par le grand nombre d'arbres qui collaborent.
   - **CritÃ¨re de dÃ©cision** : Les arbres sont entraÃ®nÃ©s Ã  partir des donnÃ©es bootstrap pour prÃ©dire une classification binaire (victoires au-dessus ou en-dessous de la mÃ©diane). Chaque arbre apprend Ã  faire des choix basÃ©s sur les variables dâ€™entrÃ©e, comme le nombre de kills, deaths, xp, etc., pour sÃ©parer les joueurs selon leur probabilitÃ© de surpasser la mÃ©diane des victoires.
3. **PrÃ©diction par Vote Majoritaire** :
   - **Principe** : Une fois tous les arbres de l'ensemble entraÃ®nÃ©s, chaque arbre effectue une prÃ©diction pour chaque Ã©chantillon en entrÃ©e (par exemple, les statistiques d'un joueur donnÃ©).
   - **Vote majoritaire** : Pour obtenir la prÃ©diction finale, toutes les prÃ©dictions individuelles des arbres sont agrÃ©gÃ©es par vote majoritaire. Si la majoritÃ© des arbres prÃ©voit que le nombre de victoires est au-dessus de la mÃ©diane, alors la prÃ©diction finale est "au-dessus". Sinon, elle est "en-dessous".
   - **Avantage** : Cette mÃ©thode rÃ©duit lâ€™impact des erreurs individuelles des arbres et renforce la stabilitÃ© des prÃ©dictions.
4. **Ã‰valuation et Suivi des Performances** :
   - **MÃ©triques de performance** : La prÃ©cision (Accuracy) et le score F1 sont utilisÃ©s pour Ã©valuer la qualitÃ© du modÃ¨le sur les ensembles dâ€™entraÃ®nement et de test. La prÃ©cision mesure la proportion de prÃ©dictions correctes, tandis que le score F1 Ã©quilibre la prÃ©cision et le rappel pour Ã©valuer les performances en classification binaire.
   - **Matrice de confusion** : Elle est utilisÃ©e pour analyser en dÃ©tail la rÃ©partition des erreurs entre les classes "au-dessus" et "en-dessous", permettant de comprendre oÃ¹ le modÃ¨le rÃ©ussit ou Ã©choue.

### SchÃ©ma du ModÃ¨le



![SchÃ©ma du ModÃ¨le](./image.png)



```
cssCopier le code[Collecte des DonnÃ©es]
      |
      v
[Ã‰chantillonnage Bootstrap]
      |       |
      |       v
      |  [Ã‰chantillon 1] ----> [Arbre de DÃ©cision 1]
      |       |
      |       v
      |  [Ã‰chantillon 2] ----> [Arbre de DÃ©cision 2]
      |       |
      |       v
      |  [Ã‰chantillon 3] ----> [Arbre de DÃ©cision 3]
      |
      v
   [Vote Majoritaire]
      |
      v
[RÃ©sultat Final : Au-dessus / En-dessous de la MÃ©diane]
```

### ParamÃ©trage du ModÃ¨le

- **Nombre d'arbres (`n_estimators`)** : 50 arbres ont Ã©tÃ© choisis aprÃ¨s des tests de performance montrant quâ€™ils offraient un bon compromis entre robustesse et coÃ»t de calcul. Un nombre plus Ã©levÃ© d'arbres peut amÃ©liorer la prÃ©cision mais augmente le temps de calcul.
- **Profondeur maximale (`max_depth`)** : LimitÃ© Ã  5 niveaux, ce choix empÃªche chaque arbre de s'adapter excessivement aux donnÃ©es dâ€™entraÃ®nement, assurant que chaque arbre reste gÃ©nÃ©ral et Ã©vite le surapprentissage.
- **CritÃ¨re de construction des arbres** : Les arbres utilisent lâ€™entropie ou le gini (selon le paramÃ©trage choisi) pour mesurer lâ€™impuretÃ© et dÃ©terminer les meilleures divisions Ã  chaque nÅ“ud, optimisant ainsi les dÃ©cisions des arbres.

### Comparaison des PrÃ©dictions avec les Valeurs RÃ©elles

En utilisant un ensemble d'arbres de dÃ©cision, le modÃ¨le atteint une **prÃ©cision de 98% sur l'ensemble de test** et un **score F1 de 98%**, ce qui montre sa capacitÃ© Ã  bien prÃ©dire la classe des victoires (au-dessus ou en-dessous de la mÃ©diane) avec peu d'erreurs. La matrice de confusion confirme l'efficacitÃ© du modÃ¨le avec un faible taux de faux positifs et de faux nÃ©gatifs.

## ğŸ“Š Comparaison avec la Distribution des Valeurs

Lâ€™application inclut des visualisations par estimation de densitÃ© de probabilitÃ© (KDE) pour chaque variable dâ€™entrÃ©e (kills, deaths, xp, etc.), permettant de comparer les valeurs de lâ€™utilisateur avec la distribution des donnÃ©es globales.

## DonnÃ©es UtilisÃ©es

- **Source** : [Kaggle](https://www.kaggle.com/datasets/fahadalqahtani/tom-clancys-rainbow-six-siege)

### Variables :

- `kills` : Nombre de kills
- `deaths` : Nombre de morts
- `losses` : Nombre de dÃ©faites
- `xp` : ExpÃ©rience accumulÃ©e
- `headshots` : Nombre de tirs Ã  la tÃªte
- `games_played` : Nombre de parties jouÃ©es
- `time_played` : Temps de jeu (en secondes)

## ğŸ“ˆ Ã‰volution des Performances du ModÃ¨le

Un graphique montre l'Ã©volution des scores de prÃ©cision et F1 sur les ensembles dâ€™entraÃ®nement et de test en fonction du nombre d'arbres. Ce suivi a permis dâ€™optimiser le nombre d'arbres pour un compromis entre performance et coÃ»t de calcul.

## Lien vers l'Application

- Application en ligne : [RainbowSixPredictionApp](https://thomas454538-rainbowsixpredictionapp-app-2zgi96.streamlit.app)

## ğŸš€ ExÃ©cution

1. Charger les donnÃ©es et le modÃ¨le dâ€™ensemble (`random_forest_model.joblib`) dans votre environnement de travail.
2. ExÃ©cuter `streamlit run app.py` pour dÃ©marrer lâ€™application.